{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ernestoruizds/DS_C3_SC1_ERNESTO_RUIZ_SANCHEZ/blob/main/DS_C3_SC1_ERNESTO_RUIZ_SANCHEZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "AamQNHdNfutA",
        "outputId": "caf651a1-ceed-4941-de44-7b46c18a544c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud del modelo Red Neuronal con 2 capas con 5 y 10 neuronas: 0.8177777777777778\n",
            "\n",
            "Matriz de confusión Red Neuronal de 2 capas con 5 y 10 neuronas\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#1.\tDeberás utilizar el archivo llamado bank_marketing.csv. con los datos de problema.\n",
        "#2.\tUtilizar el archivo bank-names.txt para obtener información de cada una de las variables.\n",
        "#3.\tCrear un proyecto tipo Jupyter Notebook en Google-Colab llamado Solucion_Reto_SC_63_ERNESTO_RUIZ.ipynb.\n",
        "#4.\tIncluye las librerías que consideres adecuadas y carga los datos del archivo en una variable llamada “data”.\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab            import drive\n",
        "from sklearn.preprocessing   import LabelEncoder, OneHotEncoder #, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model    import LogisticRegression\n",
        "from sklearn.neural_network  import MLPClassifier\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/M17/Reto/bank_marketing_RETO_DS_AS.csv\")\n",
        "\n",
        "# 5.\tObtener la información de dicha base de datos que incluya el número de registros,\n",
        "#     el total de variables, el tipo de cada variable, la cantidad de datos perdidos de cada variable en caso de que existan.\n",
        "\n",
        "data.head()\n",
        "data.info()\n",
        "\n",
        "# 6.\tTransforma las variables categóricas de manera que puedan ser tratadas numéricamente. Justifica si utilizas LabelEncoder o OneHotEcoder.\n",
        "\n",
        "# Analizamos los distintos valores de cada variable categórica\n",
        "data['job'].value_counts()       # Contiene 12 clases distintas\n",
        "data['marital'].value_counts()   # Contiene 3 clases distintas\n",
        "data['education'].value_counts() # Contiene 4 clases distintas\n",
        "data['default'].value_counts()   # Contiene 2 clases distintas (binaria)\n",
        "data['housing'].value_counts()   # Contiene 2 clases distintas (binaria)\n",
        "data['loan'].value_counts()      # Contiene 2 clases distintas (binaria)\n",
        "data['contact'].value_counts()   # Contiene 3 clases distintas\n",
        "data['month'].value_counts()     # Contiene 12 clases distintas\n",
        "data['poutcome'].value_counts()  # Contiene 4 clases distintas\n",
        "\n",
        "# Para variables categóricas con 4 categorías o menos, utilizamos el método de One-Hot\n",
        "# porque las Redes Neuronales interpretan más fácilmente las salidas One-Hot que directamente los enteros.\n",
        "# Sin embargo, pueden volverse imprácticos con variables que tienen muchos valores distintos\n",
        "# porque se crea una columna por cada valor en la variable\n",
        "\n",
        "# Inicializando OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Aplicamos one-hot encoding a las columnas con pocos valores distintintos y se crea un DataFrame con esas columnas ya transformadas\n",
        "one_hot_encoded  = encoder.fit_transform(data[['marital','education','default','housing','loan','poutcome','contact']])\n",
        "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(['marital','education','default','housing','loan','poutcome','contact']))\n",
        "\n",
        "# Se concatena el dataframe de one-hot encoded con el dataframe original. Este nuevo dataframe se llamará df_encoded\n",
        "data = pd.concat([data, one_hot_df], axis=1)\n",
        "\n",
        "# Luego quitamos las columnas que fueron transformadas porque no aportan valor al análisis\n",
        "data = data.drop(['marital','education','default','housing','loan','poutcome','contact'],axis=1)\n",
        "\n",
        "# Para variables con 4 o más de categorías, utilizamos el método de LabelEncoder; así como para la variable de salida \"y\"\n",
        "le = LabelEncoder()\n",
        "cols=['job', 'month', 'y']\n",
        "\n",
        "data[cols] = data[cols].apply(LabelEncoder().fit_transform)\n",
        "\n",
        "# 7.\tTransforma las variables numéricas en los casos que se tenga algún tipo de sesgo.\n",
        "\n",
        "# Revisamos las características de las variables numéricas (age, balance, day, duration, campaign, pdays, previous)\n",
        "data['age'].describe() # Min=18, Max=99\n",
        "data['age'].value_counts()\n",
        "\n",
        "data['balance'].describe() # Min=-3058; Max=81204\n",
        "data['balance'].value_counts()\n",
        "\n",
        "data['day'].describe() # Min=1 , Max=31\n",
        "data['day'].value_counts()\n",
        "\n",
        "data['duration'].describe() # Min=3, Max=3253\n",
        "data['duration'].value_counts()\n",
        "\n",
        "data['campaign'].describe() # Min=1 , Max=58\n",
        "data['campaign'].value_counts()\n",
        "\n",
        "data['pdays'].describe() # Min= -1, Max= 850\n",
        "data['pdays'].value_counts()\n",
        "\n",
        "data['previous'].describe() # Min=0, Max=58\n",
        "data['previous'].value_counts()\n",
        "\n",
        "# Como podemos ver, las variables \"balance\" tiene valores muy grandes y pequeños incluyendo el cero\n",
        "# De igual modo, vemos que la variable \"pdays\" tiene valores -1 y valores positivos relativamente alejados del -1\n",
        "# Las variables \"age\", \"day\", \"duration\", \"campaign\" y \"previous\" tienen valores positivos pero necesitamos ver su distribución\n",
        "\n",
        "# Ahora graficamos las variables para ver si tienen algún sesgo en su distribución\n",
        "fig, axs = plt.subplots(2,4, figsize=(10,7))\n",
        "\n",
        "age      = np.array(data['age'])\n",
        "balance  = np.array(data['balance'])\n",
        "day      = np.array(data['day'])\n",
        "duration = np.array(data['duration'])\n",
        "campaign = np.array(data['campaign'])\n",
        "pdays    = np.array(data['pdays'])\n",
        "previous = np.array(data['previous'])\n",
        "\n",
        "axs[0,0].hist(age, bins=40)\n",
        "axs[0,0].set_xlabel('Age')\n",
        "\n",
        "axs[0,1].hist(balance, bins=20)\n",
        "axs[0,1].set_xlabel('Balance')\n",
        "\n",
        "axs[0,2].hist(day, bins=40)\n",
        "axs[0,2].set_xlabel('Day')\n",
        "\n",
        "axs[0,3].hist(duration, bins=40)\n",
        "axs[0,3].set_xlabel('Duration')\n",
        "\n",
        "axs[1,0].hist(campaign, bins=20)\n",
        "axs[1,0].set_xlabel('campaign')\n",
        "\n",
        "axs[1,1].hist(pdays, bins=40)\n",
        "axs[1,1].set_xlabel('pDays')\n",
        "\n",
        "axs[1,2].hist(previous, bins=40)\n",
        "axs[1,2].set_xlabel('Previous')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Se oberva que las varibles \"age\", \"day\", \"duration\" y \"campaign\" tienen un marcado sesgo positivo (a la derecha)\n",
        "# así que se les aplicará una transformación logarítmica\n",
        "# También se puede ver que la variable \"day\" no muestra una distribución de campana\n",
        "# La variable \"balance\" tiene valores muy grandes y pequeños, incluyendo el cero\n",
        "# Hay que considerar que la variable \"pdays\" tiene valores negativos\n",
        "# y la variale \"previous\" tiene muchos datos con valor 0\n",
        "\n",
        "# Dado que la variable balance tiene valores muy grandes y pequeños, incluyendo el cero\n",
        "# Se opta por Escalar de manera Standard\n",
        "data['balance'] = (data['balance'] - data['balance'].mean()) / data['balance'].std()\n",
        "Tbalance        = np.array(data['balance'])\n",
        "\n",
        "# Dado que pDays tiene valores negativos, se opta pusar el método de min - max para transformar los datos\n",
        "data['pdays'] = (data['pdays'] - min(data['pdays'])) / (max(data['pdays']) - min(data['pdays']))\n",
        "Tdays         = np.array(data['pdays'])\n",
        "\n",
        "# Dado que \"previous\" tiene muchos datos con valor 0,se decide escalar con estandarización\n",
        "data['previous'] = (data['previous'] - data['previous'].mean()) / data['previous'].std()\n",
        "Tprevious        = np.array(data['previous'])\n",
        "\n",
        "data['age'] = np.log(data['age'])\n",
        "Tage        = np.array(data['age'])\n",
        "\n",
        "data['day'] = np.log(data['day'])\n",
        "Tday        = np.array(data['day'])\n",
        "\n",
        "data['duration'] = np.log(data['duration'])\n",
        "Tduration        = np.array(data['duration'])\n",
        "\n",
        "data['campaign'] = np.log(data['campaign'])\n",
        "Tcampaign        = np.array(data['campaign'])\n",
        "\n",
        "# Ahora revisamos cómo se distribuyeron después de haber sido transfromadas\n",
        "fig, axs2 = plt.subplots(2,4, figsize=(10,7))\n",
        "\n",
        "axs2[0,0].hist(Tage, bins=40)\n",
        "axs2[0,0].set_xlabel('Age Transformed')\n",
        "\n",
        "axs2[0,1].hist(Tbalance, bins=20)\n",
        "axs2[0,1].set_xlabel('Balance Transformed')\n",
        "\n",
        "axs2[0,2].hist(Tday, bins=40)\n",
        "axs2[0,2].set_xlabel('Day Transformed')\n",
        "\n",
        "axs2[0,3].hist(Tduration, bins=40)\n",
        "axs2[0,3].set_xlabel('Duration Transformed')\n",
        "\n",
        "axs2[1,0].hist(Tcampaign, bins=20)\n",
        "axs2[1,0].set_xlabel('Campaign Transformed')\n",
        "\n",
        "axs2[1,1].hist(Tdays, bins=40)\n",
        "axs2[1,1].set_xlabel('pDays Transformed')\n",
        "\n",
        "axs2[1,2].hist(Tprevious, bins=40)\n",
        "axs2[1,2].set_xlabel('Previous Transformed')\n",
        "\n",
        "# 8.\tConsidera la variable “y” como la variable de salida y el resto de las variables como las variables de entrada.\n",
        "# 9.\tParticiona los datos en los conjuntos de entrenamiento, validación y prueba en 60%, 20% y 20%, respectivamente.\n",
        "X = data[['age','job','balance','day','month','duration','campaign','pdays','previous','marital_divorced','marital_married','marital_single','education_primary','education_secondary','education_tertiary','education_unknown','default_no','default_yes','housing_no','housing_yes','loan_no','loan_yes','poutcome_failure','poutcome_other','poutcome_success','poutcome_unknown','contact_cellular','contact_telephone','contact_unknown']]\n",
        "Y = data[['y']]\n",
        "\n",
        "X_train, X_val_test, Y_train, Y_val_test = train_test_split(X, Y, train_size=.60)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val_test, Y_val_test, train_size=.50)\n",
        "\n",
        "# 10a.\tAplica el modelo Regresión Logística en el conjunto de entrenamiento.\n",
        "clf = LogisticRegression(C= 1.0, solver ='newton-cg', max_iter=1000)\n",
        "MRL = clf.fit(X_train, Y_train)\n",
        "\n",
        "# 10b. Valida el modelo con las predicciones del conjunto de validación y su matriz de confusión.\n",
        "print(\"Exactitud Modelo de Regresión Logística = \", MRL.score(X_val, Y_val))\n",
        "print(\"\")\n",
        "\n",
        "print(\"Iniciando pruebas con diferentes valores de parámetro C\")\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "Conf_Mtrx_01 = ConfusionMatrixDisplay.from_estimator(MRL, X_test, Y_test)\n",
        "\n",
        "# 10c. Ajusta los parámetros del modelo hasta obtener tu mejor resultado.\n",
        "# Se usarán diferentes valores de C (desde 0.25 hasta 2 en incrementos de 0.25)\n",
        "Ci = [i for i in range(25, 225, 25)]\n",
        "train_scores, val_scores = list(), list()\n",
        "train_errors, val_errors = list(), list()\n",
        "\n",
        "for i in Ci:\n",
        "  mod_clf = LogisticRegression(C= (i/100.0), solver ='newton-cg', max_iter=1000)\n",
        "\n",
        "  mod_clf.fit(X_train, np.ravel(Y_train))\n",
        "\n",
        "  # Predicciones y métricas con el conjunto de entrenamiento:\n",
        "  train_yhat = mod_clf.predict(X_train)\n",
        "  train_loss =  sum(abs(np.ravel(Y_train) - train_yhat)) / Y_train.shape[0]\n",
        "  train_errors.append(train_loss)\n",
        "  train_acc = 1 - train_loss\n",
        "  train_scores.append(train_acc)\n",
        "\n",
        "  # Predicciones y métricas con el conjunto de validación:\n",
        "  val_yhat = mod_clf.predict(X_val)\n",
        "  val_loss = sum(abs(np.ravel(Y_val) - val_yhat)) / Y_val.shape[0]\n",
        "  val_errors.append(val_loss)\n",
        "  val_acc = 1 - val_loss\n",
        "  val_scores.append(val_acc)\n",
        "\n",
        "  # Mostramos el resultado de las métricas en cada iteración\n",
        "  print('C = %.2f => trainacc: %.3f, testacc: %.3f, trainloss: %.3f, testloss: %.3f'\n",
        "        % (i/100, train_acc, val_acc, train_loss, val_loss))\n",
        "\n",
        "# Generamos la gráfica de la exactitud para predecir, usando los datos de entrenamiento y de validación\n",
        "fig, axs = plt.subplots()\n",
        "plt.plot(Ci, train_scores, '-o', label='Train')\n",
        "plt.plot(Ci, val_scores, '-o', label='Val')\n",
        "plt.title(\"C vs Exactitud\")\n",
        "plt.xlabel(\"C\")\n",
        "plt.ylabel(\"Exactitud\")\n",
        "plt.legend()\n",
        "\n",
        "fig, axse = plt.subplots()\n",
        "plt.plot(Ci, train_errors, '-o', label='Train')\n",
        "plt.plot(Ci, val_errors, '-o', label='Val')\n",
        "plt.title(\"C vs Errores\")\n",
        "plt.xlabel(\"C\")\n",
        "plt.ylabel(\"Errores\")\n",
        "plt.legend()\n",
        "\n",
        "# Para esta corrida, el mejor pronóstico fue con un C=0.5\n",
        "# Se ajusta el parámetro C a 0.5\n",
        "clf2 = LogisticRegression(C= 0.5, solver ='newton-cg', max_iter=1000)\n",
        "MRL2 = clf2.fit(X_train, Y_train)\n",
        "\n",
        "print(\"Exactitud del Modelo de Regresión Logística después de ajustar parámetros = \", MRL2.score(X_val, Y_val))\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "\n",
        "print(\"Matriz de confusión de Regresión Logística después de ajustar parámetros\")\n",
        "Conf_Mtrx_02 = ConfusionMatrixDisplay.from_estimator(MRL2, X_test, Y_test)\n",
        "\n",
        "# 11a.\tAplica el modelo Red Neuronal en el conjunto de entrenamiento.\n",
        "print(\"Iniciando análisis usando Redes Neuronales...\")\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "print(\"Primer modelo con 1 capa de 5 neuronas\")\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes = (5),\n",
        "                      max_iter=1000,\n",
        "                      learning_rate_init=0.001)\n",
        "\n",
        "model.fit(X_train, np.ravel(Y_train))\n",
        "\n",
        "train_yhat = model.predict(X_train)\n",
        "train_loss =  sum(abs(np.ravel(Y_train) - train_yhat)) / Y_train.shape[0]\n",
        "train_errors.append(train_loss)\n",
        "train_acc = 1 - train_loss\n",
        "train_scores.append(train_acc)\n",
        "\n",
        "# Predicciones y métricas con el conjunto de validación:\n",
        "val_yhat = model.predict(X_val)\n",
        "val_loss = sum(abs(np.ravel(Y_val) - val_yhat)) / Y_val.shape[0]\n",
        "val_errors.append(val_loss)\n",
        "val_acc = 1 - val_loss\n",
        "val_scores.append(val_acc)\n",
        "\n",
        "# 11b. Valida el modelo con las predicciones del conjunto de validación y su matriz de confusión.\n",
        "print('Exactitud del modelo Red Neuronal con 1 capa de 5 neuronas:', model.score(X_test, Y_test))\n",
        "\n",
        "print(\"Matriz de confusión Red Neuronal de 1 capa con 5 neuronas\")\n",
        "Conf_Mtrx_RN01 = ConfusionMatrixDisplay.from_estimator(model, X_test, Y_test)\n",
        "\n",
        "print( \"-----------------------------------------------------------------------\")\n",
        "print(\"Analizando modelos con 1 o 2 capas y diferente cantidad de neuronas por capa\")\n",
        "print(\"------------------------------------------------------------------------\")\n",
        "\n",
        "# 11c. Ajusta los parámetros del modelo hasta obtener tu mejor modelo, entre ellos el número de neuronas y capas ocultas.\n",
        "train_scores, val_scores = list(), list()\n",
        "train_errors, val_errors = list(), list()\n",
        "\n",
        "# Inicializamos variables para armado de combinaciones de capas y neuronas por capa\n",
        "wl = list()\n",
        "lst = list()\n",
        "i = 1\n",
        "# Inicio de armado de combinaciones\n",
        "# El resultado será 1 capa con 5 neuronas, otra capa con 10 neuronas y 2 capas con 5 y 10 neuronas\n",
        "for c in range(1, 3, 1):\n",
        "    for n in range(5, 11, 5):\n",
        "        if (i < c ):\n",
        "            wl.append(n)\n",
        "            i = i + 1\n",
        "        else:\n",
        "            wl.append(n)\n",
        "            lst.append(wl)\n",
        "            wl = []\n",
        "            i = 1\n",
        "\n",
        "for i in lst:\n",
        "  model = MLPClassifier(hidden_layer_sizes = (i),\n",
        "                        max_iter=1000,\n",
        "                        learning_rate_init=0.001)\n",
        "\n",
        "  model.fit(X_train, np.ravel(Y_train))\n",
        "\n",
        "  # Predicciones y métricas con el conjunto de entrenamiento:\n",
        "  train_yhat = model.predict(X_train)\n",
        "  train_loss =  sum(abs(np.ravel(Y_train) - train_yhat)) / Y_train.shape[0]\n",
        "  train_errors.append(train_loss)\n",
        "  train_acc = 1 - train_loss\n",
        "  train_scores.append(train_acc)\n",
        "\n",
        "  # Predicciones y métricas con el conjunto de validación:\n",
        "  val_yhat = model.predict(X_val)\n",
        "  val_loss = sum(abs(np.ravel(Y_val) - val_yhat)) / Y_val.shape[0]\n",
        "  val_errors.append(val_loss)\n",
        "  val_acc = 1 - val_loss\n",
        "  val_scores.append(val_acc)\n",
        "\n",
        "  # Mostramos el resultado de las métricas en cada iteración\n",
        "  print(i, '> trainacc: %.3f, testacc: %.3f, trainloss: %.3f, testloss: %.3f'\n",
        "        % (train_acc, val_acc, train_loss, val_loss))\n",
        "\n",
        "fig, axs = plt.subplots()\n",
        "plt.plot([5,10,15], train_scores, '-o', label='Train')\n",
        "plt.plot([5,10,15], val_scores, '-o', label='Val')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.title('Neuronas vs Exactitud')\n",
        "plt.xlabel('Neuronas en modelo MLP')\n",
        "plt.ylabel('Exactitud')\n",
        "plt.show()\n",
        "\n",
        "plt.plot([50,100,150], train_errors, '-o', label='Train')\n",
        "plt.plot([50,100,150], val_errors, '-o', label='Val')\n",
        "plt.legend()\n",
        "\n",
        "plt.title('Neuronas vs Error')\n",
        "plt.xlabel('Neuronas en modelo MLP')\n",
        "plt.ylabel('Error')\n",
        "plt.show()\n",
        "\n",
        "# El mejor valor obtenido fue con 1 capa con 10 neuronas\n",
        "model = MLPClassifier(hidden_layer_sizes = (10),\n",
        "                      max_iter=1000,\n",
        "                      learning_rate_init=0.001)\n",
        "\n",
        "model.fit(X_train, np.ravel(Y_train))\n",
        "\n",
        "train_yhat = model.predict(X_train)\n",
        "train_loss =  sum(abs(np.ravel(Y_train) - train_yhat)) / Y_train.shape[0]\n",
        "train_errors.append(train_loss)\n",
        "train_acc = 1 - train_loss\n",
        "train_scores.append(train_acc)\n",
        "\n",
        "# Predicciones y métricas con el conjunto de validación:\n",
        "val_yhat = model.predict(X_val)\n",
        "val_loss = sum(abs(np.ravel(Y_val) - val_yhat)) / Y_val.shape[0]\n",
        "val_errors.append(val_loss)\n",
        "val_acc = 1 - val_loss\n",
        "val_scores.append(val_acc)\n",
        "\n",
        "# 12.\tSelecciona el mejor modelo encontrado en los incisos anteriores\n",
        "# y utiliza el conjunto de prueba para obtener el desempeño final del modelo y su matriz de confusión.\n",
        "print('Exactitud del modelo Red Neuronal con 2 capas con 5 y 10 neuronas:', model.score(X_test, Y_test))\n",
        "print()\n",
        "print(\"Matriz de confusión Red Neuronal de 2 capas con 5 y 10 neuronas\")\n",
        "Conf_Mtrx_RN02 = ConfusionMatrixDisplay.from_estimator(model, X_test, Y_test)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzZx5KDcxNW5CNd3XDMYwJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}